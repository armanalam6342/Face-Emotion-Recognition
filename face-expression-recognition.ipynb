{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing all the required Libraries\n\nimport tensorflow as tf \nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential                                                            \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization,Activation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import Model\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np \nimport cv2\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:14:23.875235Z","iopub.execute_input":"2021-12-30T12:14:23.875525Z","iopub.status.idle":"2021-12-30T12:14:23.883282Z","shell.execute_reply.started":"2021-12-30T12:14:23.875490Z","shell.execute_reply":"2021-12-30T12:14:23.882154Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:14:24.227023Z","iopub.execute_input":"2021-12-30T12:14:24.227282Z","iopub.status.idle":"2021-12-30T12:14:24.231839Z","shell.execute_reply.started":"2021-12-30T12:14:24.227254Z","shell.execute_reply":"2021-12-30T12:14:24.230853Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/face-expression-recognition-dataset/images/train'","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:14:25.106431Z","iopub.execute_input":"2021-12-30T12:14:25.106991Z","iopub.status.idle":"2021-12-30T12:14:25.110665Z","shell.execute_reply.started":"2021-12-30T12:14:25.106953Z","shell.execute_reply":"2021-12-30T12:14:25.109983Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"val_path = '../input/face-expression-recognition-dataset/images/validation'","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:14:25.490060Z","iopub.execute_input":"2021-12-30T12:14:25.490322Z","iopub.status.idle":"2021-12-30T12:14:25.494195Z","shell.execute_reply.started":"2021-12-30T12:14:25.490291Z","shell.execute_reply":"2021-12-30T12:14:25.493512Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"os.listdir(train_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:14:26.853652Z","iopub.execute_input":"2021-12-30T12:14:26.853903Z","iopub.status.idle":"2021-12-30T12:14:26.870982Z","shell.execute_reply.started":"2021-12-30T12:14:26.853875Z","shell.execute_reply":"2021-12-30T12:14:26.870340Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"os.listdir(val_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:14:27.397505Z","iopub.execute_input":"2021-12-30T12:14:27.398251Z","iopub.status.idle":"2021-12-30T12:14:27.408254Z","shell.execute_reply.started":"2021-12-30T12:14:27.398214Z","shell.execute_reply":"2021-12-30T12:14:27.407258Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"categories = os.listdir(train_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:14:28.746753Z","iopub.execute_input":"2021-12-30T12:14:28.747549Z","iopub.status.idle":"2021-12-30T12:14:28.751667Z","shell.execute_reply.started":"2021-12-30T12:14:28.747497Z","shell.execute_reply":"2021-12-30T12:14:28.750967Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Creating a function for using for show some images from each categories\ndef imageshow(category):\n  plt.figure(figsize= (8,8))\n  for i in range(1, 10, 1):\n      plt.subplot(3,3,i)\n      img = load_img(train_path+'/'+category+\"/\"+\n                    os.listdir(train_path + \"/\" + category)[i], target_size=(48,48))\n      plt.imshow(img)\n  plt.suptitle(category,fontsize=30)   \n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:57.884879Z","iopub.execute_input":"2021-12-29T12:00:57.885674Z","iopub.status.idle":"2021-12-29T12:00:57.892502Z","shell.execute_reply.started":"2021-12-29T12:00:57.885638Z","shell.execute_reply":"2021-12-29T12:00:57.891798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category neutral\nimageshow('neutral')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:57.893832Z","iopub.execute_input":"2021-12-29T12:00:57.89454Z","iopub.status.idle":"2021-12-29T12:00:58.970071Z","shell.execute_reply.started":"2021-12-29T12:00:57.894506Z","shell.execute_reply":"2021-12-29T12:00:58.969323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category angry\nimageshow('angry')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:00:58.97108Z","iopub.execute_input":"2021-12-29T12:00:58.971338Z","iopub.status.idle":"2021-12-29T12:01:00.021245Z","shell.execute_reply.started":"2021-12-29T12:00:58.971305Z","shell.execute_reply":"2021-12-29T12:01:00.020539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category sad\nimageshow('sad')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:01:00.022336Z","iopub.execute_input":"2021-12-29T12:01:00.023927Z","iopub.status.idle":"2021-12-29T12:01:01.191363Z","shell.execute_reply.started":"2021-12-29T12:01:00.023888Z","shell.execute_reply":"2021-12-29T12:01:01.190684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category surprise\nimageshow('surprise')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:01:01.192409Z","iopub.execute_input":"2021-12-29T12:01:01.192756Z","iopub.status.idle":"2021-12-29T12:01:02.394277Z","shell.execute_reply.started":"2021-12-29T12:01:01.192724Z","shell.execute_reply":"2021-12-29T12:01:02.393544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category happy\nimageshow('happy')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:01:02.395454Z","iopub.execute_input":"2021-12-29T12:01:02.396183Z","iopub.status.idle":"2021-12-29T12:01:03.498811Z","shell.execute_reply.started":"2021-12-29T12:01:02.396143Z","shell.execute_reply":"2021-12-29T12:01:03.498019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category disgust\nimageshow('disgust')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:01:03.502369Z","iopub.execute_input":"2021-12-29T12:01:03.502684Z","iopub.status.idle":"2021-12-29T12:01:04.360265Z","shell.execute_reply.started":"2021-12-29T12:01:03.502648Z","shell.execute_reply":"2021-12-29T12:01:04.359606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category fear\nimageshow('fear')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:01:04.361568Z","iopub.execute_input":"2021-12-29T12:01:04.362029Z","iopub.status.idle":"2021-12-29T12:01:05.570219Z","shell.execute_reply.started":"2021-12-29T12:01:04.361984Z","shell.execute_reply":"2021-12-29T12:01:05.569592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Showing some images from validation set","metadata":{}},{"cell_type":"code","source":"# validation set images\nfor category in categories:\n    plt.figure(figsize= (8,8))\n    for j in range(1,10,1):\n        \n        plt.subplot(3,3,j)\n        \n        img = load_img(val_path+'/'+category+\"/\"+\n                    os.listdir(val_path + \"/\" + category)[j], target_size=(48,48))\n        plt.imshow(img)\n    plt.suptitle(category,fontsize=30)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:01:05.57156Z","iopub.execute_input":"2021-12-29T12:01:05.572036Z","iopub.status.idle":"2021-12-29T12:01:11.928336Z","shell.execute_reply.started":"2021-12-29T12:01:05.571984Z","shell.execute_reply":"2021-12-29T12:01:11.927601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Count of images in each category**","metadata":{}},{"cell_type":"code","source":"# count of training images\nfor expression in os.listdir(train_path):\n    print(str(len(os.listdir(train_path +'/' +expression))) + \" \" + expression + \" images\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:01:11.929426Z","iopub.execute_input":"2021-12-29T12:01:11.929686Z","iopub.status.idle":"2021-12-29T12:01:11.948083Z","shell.execute_reply.started":"2021-12-29T12:01:11.929651Z","shell.execute_reply":"2021-12-29T12:01:11.947426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count of validation images\nfor expression in os.listdir(val_path):\n    print(str(len(os.listdir(val_path +'/' +expression))) + \" \" + expression + \" images\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T12:01:11.949165Z","iopub.execute_input":"2021-12-29T12:01:11.949399Z","iopub.status.idle":"2021-12-29T12:01:11.961622Z","shell.execute_reply.started":"2021-12-29T12:01:11.949367Z","shell.execute_reply":"2021-12-29T12:01:11.960831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data prepration for Self constructed models","metadata":{}},{"cell_type":"code","source":"# Data Augumentation\ntrain_scale = ImageDataGenerator(rescale=1./255)\n    \nval_scale = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:14:43.878450Z","iopub.execute_input":"2021-12-30T12:14:43.879006Z","iopub.status.idle":"2021-12-30T12:14:43.884415Z","shell.execute_reply.started":"2021-12-30T12:14:43.878969Z","shell.execute_reply":"2021-12-30T12:14:43.883662Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"batch_size  = 64\n\ntrain_data = train_scale.flow_from_directory(train_path,\n                                  target_size = (48,48),\n                                  color_mode = \"grayscale\",\n                                  batch_size=batch_size,\n                                  class_mode='categorical',\n                                  shuffle=True)\n\nval_data = val_scale.flow_from_directory(val_path,\n                                  target_size = (48,48),\n                                  color_mode = \"grayscale\",\n                                  batch_size=batch_size,\n                                  class_mode='categorical',\n                                  shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:14:52.688215Z","iopub.execute_input":"2021-12-30T12:14:52.688735Z","iopub.status.idle":"2021-12-30T12:15:11.154095Z","shell.execute_reply.started":"2021-12-30T12:14:52.688699Z","shell.execute_reply":"2021-12-30T12:15:11.153348Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"> # **Model Building**","metadata":{}},{"cell_type":"markdown","source":"#  **Self constructed model**","metadata":{}},{"cell_type":"code","source":"emotion_model = Sequential()\n\nemotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\nemotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nemotion_model.add(MaxPooling2D(pool_size=(2, 2)))\nemotion_model.add(Dropout(0.25))\n\nemotion_model.add(Flatten())\nemotion_model.add(Dense(1024, activation='relu'))\nemotion_model.add(Dropout(0.5))\nemotion_model.add(Dense(7, activation='softmax'))\n\n\n\nemotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T13:36:43.338458Z","iopub.execute_input":"2021-12-29T13:36:43.338706Z","iopub.status.idle":"2021-12-29T13:36:43.418567Z","shell.execute_reply.started":"2021-12-29T13:36:43.338677Z","shell.execute_reply":"2021-12-29T13:36:43.41788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T13:36:57.7009Z","iopub.execute_input":"2021-12-29T13:36:57.701153Z","iopub.status.idle":"2021-12-29T13:36:57.713741Z","shell.execute_reply.started":"2021-12-29T13:36:57.701126Z","shell.execute_reply":"2021-12-29T13:36:57.7128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_data.n//train_data.batch_size\nprint('train',steps_per_epoch)\nvalidation_steps=val_data.n//val_data.batch_size\nprint('validation',validation_steps)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T13:37:05.146457Z","iopub.execute_input":"2021-12-29T13:37:05.146716Z","iopub.status.idle":"2021-12-29T13:37:05.152886Z","shell.execute_reply.started":"2021-12-29T13:37:05.146686Z","shell.execute_reply":"2021-12-29T13:37:05.152065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('Emotion_self_cons.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks = [earlystop,checkpoint,reduce_lr]","metadata":{"execution":{"iopub.status.busy":"2021-12-29T13:37:09.051687Z","iopub.execute_input":"2021-12-29T13:37:09.051984Z","iopub.status.idle":"2021-12-29T13:37:09.057883Z","shell.execute_reply.started":"2021-12-29T13:37:09.051952Z","shell.execute_reply":"2021-12-29T13:37:09.057128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model \nhistory = emotion_model.fit_generator(\n    train_data,\n    epochs=epochs,\n    validation_data = val_data,\n    callbacks=callbacks,\n    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T13:37:32.908625Z","iopub.execute_input":"2021-12-29T13:37:32.909358Z","iopub.status.idle":"2021-12-29T13:50:52.834165Z","shell.execute_reply.started":"2021-12-29T13:37:32.909321Z","shell.execute_reply":"2021-12-29T13:50:52.833439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion_model.save('self_cons_model.h5')    ","metadata":{"execution":{"iopub.status.busy":"2021-12-29T13:53:50.85379Z","iopub.execute_input":"2021-12-29T13:53:50.854391Z","iopub.status.idle":"2021-12-29T13:53:50.942651Z","shell.execute_reply.started":"2021-12-29T13:53:50.854352Z","shell.execute_reply":"2021-12-29T13:53:50.941899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# saving the history of the model in data frame \ndf=pd.DataFrame(emotion_model.history.history)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T13:53:51.462196Z","iopub.execute_input":"2021-12-29T13:53:51.462798Z","iopub.status.idle":"2021-12-29T13:53:51.468657Z","shell.execute_reply.started":"2021-12-29T13:53:51.462741Z","shell.execute_reply":"2021-12-29T13:53:51.467831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T13:53:53.624898Z","iopub.execute_input":"2021-12-29T13:53:53.625433Z","iopub.status.idle":"2021-12-29T13:53:53.637054Z","shell.execute_reply.started":"2021-12-29T13:53:53.625396Z","shell.execute_reply":"2021-12-29T13:53:53.636217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting Accuracy & Loss\nplt.style.use('dark_background')\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(df['loss'], label='Training Loss')\nplt.plot(df['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(df['accuracy'], label='Training Accuracy')\nplt.plot(df['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T13:53:55.626938Z","iopub.execute_input":"2021-12-29T13:53:55.627566Z","iopub.status.idle":"2021-12-29T13:53:55.952885Z","shell.execute_reply.started":"2021-12-29T13:53:55.627531Z","shell.execute_reply":"2021-12-29T13:53:55.952213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute predictions\npredictions = emotion_model.predict_generator(generator=val_data)\ny_pred = [np.argmax(probas) for probas in predictions]\ny_test = val_data.classes\nclass_names = val_data.class_indices.keys()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T14:05:25.010385Z","iopub.execute_input":"2021-12-29T14:05:25.010642Z","iopub.status.idle":"2021-12-29T14:05:29.459352Z","shell.execute_reply.started":"2021-12-29T14:05:25.010614Z","shell.execute_reply":"2021-12-29T14:05:29.458649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the confusion matrix of our predictions\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')# **Live Class Monitoring System(Face Emotion Recognition)**\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n# compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\n# plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, title='Normalized confusion matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T14:05:38.083034Z","iopub.execute_input":"2021-12-29T14:05:38.083286Z","iopub.status.idle":"2021-12-29T14:05:38.576258Z","shell.execute_reply.started":"2021-12-29T14:05:38.083259Z","shell.execute_reply":"2021-12-29T14:05:38.575576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data prepration for Transfer learning**","metadata":{}},{"cell_type":"code","source":"img_size = 224\nbatch_size = 32\n\n# selecting colour mode as rgb as transfer learning is trained on rgb photos and we have grascaled images\ndatagen_train = ImageDataGenerator(horizontal_flip=True,brightness_range=[0.8,1.2],rescale=1./255)\ntrain_generator = datagen_train.flow_from_directory(train_path,\n                                                  target_size=(img_size,img_size),\n                                                  batch_size=batch_size,\n                                                  shuffle=True,\n                                                  color_mode='rgb',\n                                                  class_mode='categorical')\n\ndatagen_validation = ImageDataGenerator(horizontal_flip=True,brightness_range=[0.8,1.2],rescale=1./255)\nvalidation_generator = datagen_train.flow_from_directory(val_path,\n                                                  target_size=(img_size,img_size),\n                                                  batch_size=batch_size,\n                                                  shuffle=False,\n                                                  color_mode='rgb',\n                                                  class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:15:11.155748Z","iopub.execute_input":"2021-12-30T12:15:11.156240Z","iopub.status.idle":"2021-12-30T12:15:16.240008Z","shell.execute_reply.started":"2021-12-30T12:15:11.156201Z","shell.execute_reply":"2021-12-30T12:15:16.239250Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# **Model Vgg16**","metadata":{}},{"cell_type":"code","source":"#using pretrained model, VGG16 architecture\nfrom tensorflow.keras.applications.vgg16 import VGG16","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:15:31.912358Z","iopub.execute_input":"2021-12-30T12:15:31.912800Z","iopub.status.idle":"2021-12-30T12:15:31.919066Z","shell.execute_reply.started":"2021-12-30T12:15:31.912755Z","shell.execute_reply":"2021-12-30T12:15:31.918290Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# creating a base model using resnet and loading the pretrained weights\nbase_model = VGG16(input_shape=(224,224,3),include_top = False, weights = 'imagenet')\nbase_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:55:12.971443Z","iopub.execute_input":"2021-12-30T05:55:12.971760Z","iopub.status.idle":"2021-12-30T05:55:13.318342Z","shell.execute_reply.started":"2021-12-30T05:55:12.971725Z","shell.execute_reply":"2021-12-30T05:55:13.317656Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# making all the layers except last layer non trainable \nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:56:15.785180Z","iopub.execute_input":"2021-12-30T05:56:15.785460Z","iopub.status.idle":"2021-12-30T05:56:15.790086Z","shell.execute_reply.started":"2021-12-30T05:56:15.785432Z","shell.execute_reply":"2021-12-30T05:56:15.789083Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# our layers - you can add more if you want\nx = Flatten()(base_model.output)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:56:19.010131Z","iopub.execute_input":"2021-12-30T05:56:19.010454Z","iopub.status.idle":"2021-12-30T05:56:19.023146Z","shell.execute_reply.started":"2021-12-30T05:56:19.010420Z","shell.execute_reply":"2021-12-30T05:56:19.022324Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"prediction = Dense(7, activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:56:20.007071Z","iopub.execute_input":"2021-12-30T05:56:20.007329Z","iopub.status.idle":"2021-12-30T05:56:20.023544Z","shell.execute_reply.started":"2021-12-30T05:56:20.007300Z","shell.execute_reply":"2021-12-30T05:56:20.022876Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# create a model object\nmodel = Model(inputs=base_model.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:56:23.353088Z","iopub.execute_input":"2021-12-30T05:56:23.354045Z","iopub.status.idle":"2021-12-30T05:56:23.363231Z","shell.execute_reply.started":"2021-12-30T05:56:23.353988Z","shell.execute_reply":"2021-12-30T05:56:23.362308Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:56:25.654601Z","iopub.execute_input":"2021-12-30T05:56:25.655279Z","iopub.status.idle":"2021-12-30T05:56:25.670882Z","shell.execute_reply.started":"2021-12-30T05:56:25.655241Z","shell.execute_reply":"2021-12-30T05:56:25.670168Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:56:29.005627Z","iopub.execute_input":"2021-12-30T05:56:29.005941Z","iopub.status.idle":"2021-12-30T05:56:29.017449Z","shell.execute_reply.started":"2021-12-30T05:56:29.005886Z","shell.execute_reply":"2021-12-30T05:56:29.016537Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_generator.n//train_generator.batch_size\nprint(steps_per_epoch)\nvalidation_steps=validation_generator.n//validation_generator.batch_size\nprint(validation_steps)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:56:41.879398Z","iopub.execute_input":"2021-12-30T05:56:41.879999Z","iopub.status.idle":"2021-12-30T05:56:41.888575Z","shell.execute_reply.started":"2021-12-30T05:56:41.879959Z","shell.execute_reply":"2021-12-30T05:56:41.886325Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\n# this decreases the learning rate if the model loss does not decrease \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=10, min_lr=0.00001, mode='auto')\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights_vgg16.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=10,\n                            verbose=1,\n                            restore_best_weights=True)\ncallbacks = [checkpoint, reduce_lr,early_stopping]","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:56:48.556438Z","iopub.execute_input":"2021-12-30T05:56:48.556712Z","iopub.status.idle":"2021-12-30T05:56:48.562303Z","shell.execute_reply.started":"2021-12-30T05:56:48.556682Z","shell.execute_reply":"2021-12-30T05:56:48.561476Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n  train_generator,\n  validation_data=validation_generator,\n  epochs=50,\n  steps_per_epoch=steps_per_epoch,\n  validation_steps=validation_steps,\ncallbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T05:59:29.150640Z","iopub.execute_input":"2021-12-30T05:59:29.150923Z","iopub.status.idle":"2021-12-30T06:47:22.024355Z","shell.execute_reply.started":"2021-12-30T05:59:29.150893Z","shell.execute_reply":"2021-12-30T06:47:22.023619Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# **MObileNet**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet import MobileNet","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:17:46.389751Z","iopub.execute_input":"2021-12-30T12:17:46.390010Z","iopub.status.idle":"2021-12-30T12:17:46.394648Z","shell.execute_reply.started":"2021-12-30T12:17:46.389981Z","shell.execute_reply":"2021-12-30T12:17:46.393910Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"mobile_net = MobileNet(input_shape = (224,224,3),include_top = False,weights = \"imagenet\")","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:17:46.701557Z","iopub.execute_input":"2021-12-30T12:17:46.702029Z","iopub.status.idle":"2021-12-30T12:17:49.886313Z","shell.execute_reply.started":"2021-12-30T12:17:46.701991Z","shell.execute_reply":"2021-12-30T12:17:49.885585Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# making all the layers except last layer non trainable \nfor layer in mobile_net.layers:\n    layer.trainable = False\n","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:23:49.265203Z","iopub.execute_input":"2021-12-30T12:23:49.265474Z","iopub.status.idle":"2021-12-30T12:23:49.272989Z","shell.execute_reply.started":"2021-12-30T12:23:49.265431Z","shell.execute_reply":"2021-12-30T12:23:49.272315Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# our layers - you can add more if you want\nx = Flatten()(mobile_net.output)\nprediction = Dense(7, activation='softmax')(x)\n# create a model object\nmodel = Model(inputs=mobile_net.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:25:20.119497Z","iopub.execute_input":"2021-12-30T12:25:20.119770Z","iopub.status.idle":"2021-12-30T12:25:20.144171Z","shell.execute_reply.started":"2021-12-30T12:25:20.119740Z","shell.execute_reply":"2021-12-30T12:25:20.143509Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.layers import Flatten, Dense, GlobalAvgPool2D, GlobalMaxPool2D\n\n# x = mobile_net.layers[-14].output\n\n# global_pool = GlobalMaxPool2D(name=\"global_pool\")(x)\n\n# output = Dense(7, activation=\"softmax\", name=\"out_layer\")(global_pool)\n\n# model = Model(inputs=mobile_net.input, outputs=output)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:20:51.772734Z","iopub.execute_input":"2021-12-30T12:20:51.773475Z","iopub.status.idle":"2021-12-30T12:20:51.796980Z","shell.execute_reply.started":"2021-12-30T12:20:51.773412Z","shell.execute_reply":"2021-12-30T12:20:51.796291Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:25:32.422394Z","iopub.execute_input":"2021-12-30T12:25:32.422943Z","iopub.status.idle":"2021-12-30T12:25:32.466997Z","shell.execute_reply.started":"2021-12-30T12:25:32.422905Z","shell.execute_reply":"2021-12-30T12:25:32.466307Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    optimizers.Adam(0.01),\n]\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optims[1],\n        metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:26:34.040233Z","iopub.execute_input":"2021-12-30T12:26:34.040506Z","iopub.status.idle":"2021-12-30T12:26:34.056269Z","shell.execute_reply.started":"2021-12-30T12:26:34.040456Z","shell.execute_reply":"2021-12-30T12:26:34.055594Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\n# this decreases the learning rate if the model loss does not decrease \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=10, min_lr=0.00001, mode='auto')\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights_mobile_net.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=10,\n                            verbose=1,\n                            restore_best_weights=True)\ncallbacks = [checkpoint, reduce_lr,early_stopping]","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:26:53.160185Z","iopub.execute_input":"2021-12-30T12:26:53.161111Z","iopub.status.idle":"2021-12-30T12:26:53.167559Z","shell.execute_reply.started":"2021-12-30T12:26:53.161051Z","shell.execute_reply":"2021-12-30T12:26:53.166824Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\n# early_stopping = EarlyStopping(\n#     monitor='val_accuracy',\n#     min_delta=0.00008,\n#     patience=11,\n#     verbose=1,\n#     restore_best_weights=True,\n# )\n# # to save model weights \n# checkpoint = ModelCheckpoint(\"model_weights_mobilenet.h5\", monitor='val_accuracy',\n#                              save_weights_only=True, mode='max', verbose=1)\n# lr_scheduler = ReduceLROnPlateau(\n#     monitor='val_accuracy',\n#     min_delta=0.0001,\n#     factor=0.25,\n#     patience=4,\n#     min_lr=1e-7,\n#     verbose=1,\n# )\n\n# callbacks = [\n#     early_stopping,\n#     lr_scheduler,\n#     checkpoint\n# ]","metadata":{"execution":{"iopub.status.busy":"2021-12-30T07:19:24.119422Z","iopub.execute_input":"2021-12-30T07:19:24.120295Z","iopub.status.idle":"2021-12-30T07:19:24.126113Z","shell.execute_reply.started":"2021-12-30T07:19:24.120256Z","shell.execute_reply":"2021-12-30T07:19:24.125420Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_generator.n//train_generator.batch_size\nprint(steps_per_epoch)\nvalidation_steps=validation_generator.n//validation_generator.batch_size\nprint(validation_steps)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:27:58.018033Z","iopub.execute_input":"2021-12-30T12:27:58.018304Z","iopub.status.idle":"2021-12-30T12:27:58.024925Z","shell.execute_reply.started":"2021-12-30T12:27:58.018273Z","shell.execute_reply":"2021-12-30T12:27:58.024029Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n  train_generator,\n  validation_data=validation_generator,\n  epochs=50,\n  steps_per_epoch=steps_per_epoch,\n  validation_steps=validation_steps,\ncallbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:28:18.489625Z","iopub.execute_input":"2021-12-30T12:28:18.490424Z","iopub.status.idle":"2021-12-30T12:55:28.153929Z","shell.execute_reply.started":"2021-12-30T12:28:18.490375Z","shell.execute_reply":"2021-12-30T12:55:28.153149Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model.save('model')","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:56:21.675287Z","iopub.execute_input":"2021-12-30T12:56:21.675889Z","iopub.status.idle":"2021-12-30T12:57:13.273084Z","shell.execute_reply.started":"2021-12-30T12:56:21.675850Z","shell.execute_reply":"2021-12-30T12:57:13.272307Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model.save('mobile_net.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-30T12:58:15.014453Z","iopub.execute_input":"2021-12-30T12:58:15.014962Z","iopub.status.idle":"2021-12-30T12:58:15.262279Z","shell.execute_reply.started":"2021-12-30T12:58:15.014926Z","shell.execute_reply":"2021-12-30T12:58:15.261358Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom time import sleep\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing import image\nimport cv2\nimport numpy as np\nimport tensorflow as tf\n\nface_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') # Face Detection\nclassifier =load_model(\"./mobile_net.h5\")  #Load model\n\nemotion_labels = ['Angry','Disgust','Fear','Happy','Neutral', 'Sad', 'Surprise']  # Emotion that will be predicted\n\ncap = cv2.VideoCapture(0)  ## Opening webcam\n\n\n\nwhile True:\n    _, frame = cap.read()\n    labels = []\n    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n    faces = face_classifier.detectMultiScale(gray)\n\n    for (x,y,w,h) in faces:\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n        roi_gray = gray[y:y+h,x:x+w]\n        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)  ##Face Cropping for prediction\n\n\n\n        if np.sum([roi_gray])!=0:\n            roi = roi_gray.astype('float')/255.0\n            roi = img_to_array(roi)\n            roi = np.expand_dims(roi,axis=0) ## reshaping the cropped face image for prediction\n\n            prediction = classifier.predict(roi)[0]   #Prediction\n            label=emotion_labels[prediction.argmax()]\n            label_position = (x,y)\n            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)   # Text Adding\n        else:\n            cv2.putText(frame,'No Faces',(30,80),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n    cv2.imshow('Emotion Detector',frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:18:50.369998Z","iopub.execute_input":"2021-12-30T13:18:50.370266Z","iopub.status.idle":"2021-12-30T13:18:51.004276Z","shell.execute_reply.started":"2021-12-30T13:18:50.370235Z","shell.execute_reply":"2021-12-30T13:18:51.003293Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}