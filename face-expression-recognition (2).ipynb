{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing all the required Libraries\n\nimport tensorflow as tf \nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential                                                            \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization,GlobalMaxPool2D,Activation,GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import Model\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import optimizers\nimport numpy as np \nimport cv2\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-01-03T10:54:54.207577Z","iopub.execute_input":"2022-01-03T10:54:54.207854Z","iopub.status.idle":"2022-01-03T10:55:00.583682Z","shell.execute_reply.started":"2022-01-03T10:54:54.207808Z","shell.execute_reply":"2022-01-03T10:55:00.582964Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# storing training path in a variable \ntrain_path = '../input/face-expression-recognition-dataset/images/train'\n\n# storing training path in a variable \nval_path = '../input/face-expression-recognition-dataset/images/validation'","metadata":{"execution":{"iopub.status.busy":"2022-01-03T09:42:30.552816Z","iopub.execute_input":"2022-01-03T09:42:30.553187Z","iopub.status.idle":"2022-01-03T09:42:30.562587Z","shell.execute_reply.started":"2022-01-03T09:42:30.553147Z","shell.execute_reply":"2022-01-03T09:42:30.560466Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# All categories are stored in a varible\ncategories = os.listdir(train_path)\nprint(categories)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T09:42:30.565717Z","iopub.execute_input":"2022-01-03T09:42:30.566539Z","iopub.status.idle":"2022-01-03T09:42:30.591355Z","shell.execute_reply.started":"2022-01-03T09:42:30.566491Z","shell.execute_reply":"2022-01-03T09:42:30.590389Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**We can see there are 7 diffrent face expression**","metadata":{}},{"cell_type":"code","source":"# Creating a function for using for show some images from each categories\ndef imageshow(category):\n  plt.figure(figsize= (8,8))\n  for i in range(1, 10, 1):\n      plt.subplot(3,3,i)\n      img = load_img(train_path+'/'+category+\"/\"+\n                    os.listdir(train_path + \"/\" + category)[i], target_size=(48,48))\n      plt.imshow(img)\n  plt.suptitle(category,fontsize=30)   \n  plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Showing some images from training set","metadata":{}},{"cell_type":"code","source":"#Showing some images from category neutral\nimageshow('neutral')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category angry\nimageshow('angry')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category sad\nimageshow('sad')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category surprise\nimageshow('surprise')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category happy\nimageshow('happy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category disgust\nimageshow('disgust')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category fear\nimageshow('fear')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Showing some images from validation set","metadata":{}},{"cell_type":"code","source":"# validation set images\nfor category in categories:\n    plt.figure(figsize= (8,8))\n    for j in range(1,10,1):\n        \n        plt.subplot(3,3,j)\n        \n        img = load_img(val_path+'/'+category+\"/\"+\n                    os.listdir(val_path + \"/\" + category)[j], target_size=(48,48))\n        plt.imshow(img)\n    plt.suptitle(category,fontsize=30)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Count of images in each category**","metadata":{}},{"cell_type":"code","source":"# count of training images\nfor expression in os.listdir(train_path):\n    print(str(len(os.listdir(train_path +'/' +expression))) + \" \" + expression + \" images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count of validation images\nfor expression in os.listdir(val_path):\n    print(str(len(os.listdir(val_path +'/' +expression))) + \" \" + expression + \" images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data prepration for Self constructed models","metadata":{}},{"cell_type":"code","source":"# Data Augumentation\naugumentation_train = ImageDataGenerator(\n                rescale=1./255,\n                rotation_range = 10,\n                horizontal_flip = True,\n                width_shift_range=0.1,\n                height_shift_range=0.1,\n                fill_mode = 'nearest'\n                )\n\naugumentation_test = ImageDataGenerator(\n                rescale=1./255,)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T09:42:30.594045Z","iopub.execute_input":"2022-01-03T09:42:30.594360Z","iopub.status.idle":"2022-01-03T09:42:30.601366Z","shell.execute_reply.started":"2022-01-03T09:42:30.594317Z","shell.execute_reply":"2022-01-03T09:42:30.600281Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"batch_size  = 128\n\ntrain_data = augumentation_train.flow_from_directory(\n                    train_path,\n                    color_mode='grayscale',\n                    target_size=(48,48),\n                    batch_size=batch_size,\n                    class_mode='categorical',\n                    shuffle=True)\n\nvalidation_data = augumentation_test.flow_from_directory(\n                            val_path,\n                            color_mode='grayscale',\n                            target_size=(48,48),\n                            batch_size=batch_size,\n                            class_mode='categorical',\n                            shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T09:42:30.603057Z","iopub.execute_input":"2022-01-03T09:42:30.603878Z","iopub.status.idle":"2022-01-03T09:42:39.800577Z","shell.execute_reply.started":"2022-01-03T09:42:30.603832Z","shell.execute_reply":"2022-01-03T09:42:39.799566Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"> # **Model Building**","metadata":{}},{"cell_type":"markdown","source":"#  **Self constructed model**","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', padding='same',input_shape=(48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2),))\nmodel.add(Dropout(0.3,))#the 2-nd block\nmodel.add(Conv2D(128, kernel_size=3, activation='relu', padding='same',))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))#the 3-rd block\nmodel.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2),))\nmodel.add(Dropout(0.3,))#the 4-th block\nmodel.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\n#the 5-th block\nmodel.add(Conv2D(512, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, kernel_size=3, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(7, kernel_regularizer=tf.keras.regularizers.l2(0.01),activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-01-03T09:42:39.802610Z","iopub.execute_input":"2022-01-03T09:42:39.802920Z","iopub.status.idle":"2022-01-03T09:42:43.018896Z","shell.execute_reply.started":"2022-01-03T09:42:39.802862Z","shell.execute_reply":"2022-01-03T09:42:43.017955Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"## for mulitclassification\nmodel.compile(optimizer = 'adam', loss = 'squared_hinge', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T09:42:43.020622Z","iopub.execute_input":"2022-01-03T09:42:43.020890Z","iopub.status.idle":"2022-01-03T09:42:43.038515Z","shell.execute_reply.started":"2022-01-03T09:42:43.020849Z","shell.execute_reply":"2022-01-03T09:42:43.037462Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2, min_lr=0.0001, mode='auto')\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=5,\n                            verbose=1,\n                            restore_best_weights=True,)\ncallbacks = [checkpoint, reduce_lr,early_stopping]","metadata":{"execution":{"iopub.status.busy":"2022-01-03T09:42:43.039855Z","iopub.execute_input":"2022-01-03T09:42:43.040380Z","iopub.status.idle":"2022-01-03T09:42:43.049051Z","shell.execute_reply.started":"2022-01-03T09:42:43.040335Z","shell.execute_reply":"2022-01-03T09:42:43.046705Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"epochs=100\nsteps_per_epoch=train_data.n//train_data.batch_size\nprint(steps_per_epoch)\n\nvalidation_steps=validation_data.n//validation_data.batch_size\nprint(validation_steps)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T09:42:43.051131Z","iopub.execute_input":"2022-01-03T09:42:43.051885Z","iopub.status.idle":"2022-01-03T09:42:43.061364Z","shell.execute_reply.started":"2022-01-03T09:42:43.051828Z","shell.execute_reply":"2022-01-03T09:42:43.060234Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"history=model.fit(\n                train_data,\n                steps_per_epoch=steps_per_epoch,\n                epochs=100,\n                callbacks=callbacks,\n                validation_data=validation_data,\n                validation_steps=validation_steps,\n                use_multiprocessing=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T09:42:43.065508Z","iopub.execute_input":"2022-01-03T09:42:43.065955Z","iopub.status.idle":"2022-01-03T10:31:33.174783Z","shell.execute_reply.started":"2022-01-03T09:42:43.065891Z","shell.execute_reply":"2022-01-03T10:31:33.173527Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.save(\"CNN_SVM_Model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-03T10:33:51.867614Z","iopub.execute_input":"2022-01-03T10:33:51.868709Z","iopub.status.idle":"2022-01-03T10:33:52.368745Z","shell.execute_reply.started":"2022-01-03T10:33:51.868672Z","shell.execute_reply":"2022-01-03T10:33:52.367729Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialising the CNN\nmodel = Sequential()\n\n# 1 - Convolution\nmodel.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel.add(Conv2D(128,(5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 3rd Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 4th Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Flattening\nmodel.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# output layer \nmodel.add(Dense(7, activation='softmax'))\n\n# compiling the model\nopt = Adam(learning_rate=0.0005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2, min_lr=0.00001, mode='auto')\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=5,\n                            verbose=1,\n                            restore_best_weights=True)\ncallbacks = [checkpoint, reduce_lr, early_stopping]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=70\nsteps_per_epoch=train_data.n//train_data.batch_size\nprint(steps_per_epoch)\n\nvalidation_steps=validation_data.n//validation_data.batch_size\nprint(validation_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(\n                train_data,\n                steps_per_epoch=steps_per_epoch,\n                epochs=70,\n                callbacks=callbacks,\n                validation_data=validation_data,\n                validation_steps=validation_steps,\n                use_multiprocessing=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('custom_cnn_model.h5')    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('CNN_SVM_Model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-03T10:55:03.520086Z","iopub.execute_input":"2022-01-03T10:55:03.520589Z","iopub.status.idle":"2022-01-03T10:55:03.892190Z","shell.execute_reply.started":"2022-01-03T10:55:03.520555Z","shell.execute_reply":"2022-01-03T10:55:03.890103Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions=model.predict(validation_data)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T10:54:21.058827Z","iopub.execute_input":"2022-01-03T10:54:21.059391Z","iopub.status.idle":"2022-01-03T10:54:21.138622Z","shell.execute_reply.started":"2022-01-03T10:54:21.059297Z","shell.execute_reply":"2022-01-03T10:54:21.137730Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":" # Accuracy Score of Our Model\nacc=accuracy_score(y_pred=np.argmax(predictions, axis=-1),y_true=validation_data.classes)\nacc   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# saving the history of the model in data frame \ndf=pd.DataFrame(model.history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting Accuracy & Loss\nplt.style.use('dark_background')\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(df['loss'], label='Training Loss')\nplt.plot(df['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(df['accuracy'], label='Training Accuracy')\nplt.plot(df['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Accuracy Score of Our Model\nacc=accuracy_score(y_pred=np.argmax(predictions, axis=-1),y_true=validation_generator.classes)\nacc ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute predictions\npredictions = model.predict_generator(generator=validation_data)\ny_pred = [np.argmax(probas) for probas in predictions]\ny_test = validation_data.classes\nclass_names = validation_data.class_indices.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the confusion matrix of our predictions\n\n# compute predictions\npredictions = model.predict_generator(generator=validation_data)\ny_pred = [np.argmax(probas) for probas in predictions]\ny_test = validation_data.classes\nclass_names = validation_data.class_indices.keys()\n\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    plt.figure(figsize=(10,8))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')# **Live Class Monitoring System(Face Emotion Recognition)**\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n# compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\n# plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, title='Normalized confusion matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data prepration for Transfer learning**","metadata":{}},{"cell_type":"code","source":"img_size = 244\nbatch_size = 32\n\n# selecting colour mode as rgb as transfer learning is trained on rgb photos and we have grascaled images\ndatagen_train = ImageDataGenerator(rescale=1./255)   \ntrain_generator = datagen_train.flow_from_directory(train_path,\n                                                  target_size=(img_size,img_size),\n                                                  batch_size=batch_size,\n                                                  shuffle=True,\n                                                  color_mode='rgb',\n                                                  class_mode='categorical')\n\ndatagen_validation = ImageDataGenerator(rescale=1./255)\n\nvalidation_generator = datagen_validation.flow_from_directory(val_path,\n                                                  target_size=(img_size,img_size),\n                                                  batch_size=batch_size,\n                                                  shuffle=False,\n                                                  color_mode='rgb',\n                                                  class_mode='categorical')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Vgg16**","metadata":{}},{"cell_type":"code","source":"#using pretrained model, VGG16 architecture\nfrom tensorflow.keras.applications.vgg16 import VGG16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a base model using resnet and loading the pretrained weights\nbase_model = VGG16(input_shape=(224,224,3),include_top = False, weights = 'imagenet')\nbase_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making all the layers except last layer non trainable \nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# our layers - you can add more if you want\nx = Flatten()(base_model.output)\nprediction = Dense(7, activation='softmax')(x)\n# create a model object\nmodel = Model(inputs=base_model.input, outputs=prediction)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    optimizers.Adam(0.01),\n]\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optims[1],\n        metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_generator.n//train_generator.batch_size\nprint(steps_per_epoch)\n\nvalidation_steps=validation_generator.n//validation_generator.batch_size\nprint(validation_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\n# this decreases the learning rate if the model loss does not decrease \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=10, min_lr=0.00001, mode='auto')\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights_mobile_net.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=10,\n                            verbose=1,\n                            restore_best_weights=True)\ncallbacks = [checkpoint, reduce_lr,early_stopping]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n  train_generator,\n  validation_data=validation_generator,\n  epochs=50,\n  steps_per_epoch=steps_per_epoch,\n  validation_steps=validation_steps,\n  callbacks=callbacks,\n  use_multiprocessing=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('vgg16_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MObileNet**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet import MobileNet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_net = MobileNet(input_shape = (224,224,3),include_top = False,weights = \"imagenet\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making all the layers except last layer non trainable \nfor layer in mobile_net.layers:\n    layer.trainable = False\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_net = MobileNet(\n    input_shape = (224, 224, 3),\n    include_top = False,\n    weights = \"imagenet\",\n    classes = 7\n)\n\nx = mobile_net.layers[-1].output\nglobal_pool = GlobalMaxPool2D(name=\"global_pool\")(x)\nout = Dense(7, activation=\"softmax\", name=\"out_layer\")(global_pool)\n\nmodel = Model(inputs=mobile_net.input, outputs=out)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_data.n//train_data.batch_size\nprint(steps_per_epoch)\n\nvalidation_steps=val_data.n//val_data.batch_size\nprint(validation_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00008,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    min_delta=0.0001,\n    factor=0.25,\n    patience=4,\n    min_lr=1e-7,\n    verbose=1,\n)\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights_mobile_net.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n    checkpoint\n]\nbatch_size = 25\nepochs = 50\n\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    optimizers.Adam(0.01),\n]\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optims[1],\n        metrics=['accuracy']\n)\n\nhistory = model.fit_generator(\n  train_data,\n  validation_data=val_data,\n  epochs=50,\n  steps_per_epoch=steps_per_epoch,\n  validation_steps=validation_steps,\ncallbacks=callbacks,\nuse_multiprocessing=True\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    optimizers.Adam(0.01),\n]\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optims[1],\n        metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\n# this decreases the learning rate if the model loss does not decrease \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=10, min_lr=0.00001, mode='auto')\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights_mobile_net.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=10,\n                            verbose=1,\n                            restore_best_weights=True)\ncallbacks = [checkpoint, reduce_lr,early_stopping]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\n# early_stopping = EarlyStopping(\n#     monitor='val_accuracy',\n#     min_delta=0.00008,\n#     patience=11,\n#     verbose=1,\n#     restore_best_weights=True,\n# )\n# # to save model weights \n# checkpoint = ModelCheckpoint(\"model_weights_mobilenet.h5\", monitor='val_accuracy',\n#                              save_weights_only=True, mode='max', verbose=1)\n# lr_scheduler = ReduceLROnPlateau(\n#     monitor='val_accuracy',\n#     min_delta=0.0001,\n#     factor=0.25,\n#     patience=4,\n#     min_lr=1e-7,\n#     verbose=1,\n# )\n\n# callbacks = [\n#     early_stopping,\n#     lr_scheduler,\n#     checkpoint\n# ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_generator.n//train_generator.batch_size\nprint(steps_per_epoch)\nvalidation_steps=validation_generator.n//validation_generator.batch_size\nprint(validation_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n  train_generator,\n  validation_data=validation_generator,\n  epochs=50,\n  steps_per_epoch=steps_per_epoch,\n  validation_steps=validation_steps,\ncallbacks=callbacks\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('mobile_net.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Image generators, for all train, validation, and test set\ntraining_gen=ImageDataGenerator(rescale=1./255)\ntesting_gen=ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating  Training Dataset\n\ntrain_gen=training_gen.flow_from_directory(train_path,                \n                                           target_size=(48,48),\n                                           batch_size=32,\n                                           color_mode='grayscale',\n                                           class_mode='categorical')\n\n# Creating Test Set\n\ntest_gen=testing_gen.flow_from_directory(val_path,                                       \n                                           target_size=(48,48),  \n                                           batch_size=32,\n                                           color_mode='grayscale',\n                                           class_mode='categorical',\n                                           shuffle= False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.optimizers import Adam,SGD,RMSprop\n\nno_of_classes = 7\n\nmodel = Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n#output layer\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\n\nopt = Adam(lr = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding various Call Backs Like Early stopping to prevent overfitting and Decay Learning Rate to prevent Overshooting\n\ncheckpoint = ModelCheckpoint('./my_model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')          # Adding various Call Backs Like Early stopping to prevent overfitting and Decay Learning Rate to prevent Overshooting\n\n#early stopping\n\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=5,\n                            verbose=1,\n                            restore_best_weights=True)\ndecay_lr= ReduceLROnPlateau(monitor='val_loss',\n                           factor=0.2,\n                           patience=3,\n                           verbose=1,\n                           min_delta=0.0001)\ncallbacks=[early_stopping,checkpoint,decay_lr]\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fitting the generator\n\nresults = model.fit_generator(generator=train_gen,\n                                steps_per_epoch=train_gen.n//train_gen.batch_size,\n                                epochs=40,\n                                validation_data = test_gen,\n                                validation_steps = test_gen.n//test_gen.batch_size,\n                                callbacks=callbacks\n                                )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"self_cons.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG 16","metadata":{}},{"cell_type":"code","source":"# construct the training image generator for data augmentation\naug = ImageDataGenerator(\n\trotation_range=20,\n\tzoom_range=0.15,\n\twidth_shift_range=0.2,\n\theight_shift_range=0.2,\n\tshear_range=0.15,\n\thorizontal_flip=True,\n\tfill_mode=\"nearest\")\n\n# load the MobileNetV2 network, ensuring the head FC layer sets are\n# left off\nbaseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n\tinput_tensor=Input(shape=(224, 224, 3)))\n\n# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(128, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n\tlayer.trainable = False\n\n# compile our model\nprint(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n\tmetrics=[\"accuracy\"])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}