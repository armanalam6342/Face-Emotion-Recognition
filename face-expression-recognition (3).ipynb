{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing all the required Libraries\n\nimport tensorflow as tf \nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential                                                            \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization,GlobalMaxPool2D,Activation,GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import Model\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import optimizers\nimport numpy as np \nimport cv2\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-01-04T09:58:02.255607Z","iopub.execute_input":"2022-01-04T09:58:02.255915Z","iopub.status.idle":"2022-01-04T09:58:07.833376Z","shell.execute_reply.started":"2022-01-04T09:58:02.255836Z","shell.execute_reply":"2022-01-04T09:58:07.832487Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# storing training path in a variable \ntrain_path = '../input/face-expression-recognition-dataset/images/train'\n\n# storing training path in a variable \nval_path = '../input/face-expression-recognition-dataset/images/validation'","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:30:43.366459Z","iopub.execute_input":"2022-01-04T10:30:43.366711Z","iopub.status.idle":"2022-01-04T10:30:43.370671Z","shell.execute_reply.started":"2022-01-04T10:30:43.366683Z","shell.execute_reply":"2022-01-04T10:30:43.369637Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# All categories are stored in a varible\ncategories = os.listdir(train_path)\nprint(categories)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:30:43.659959Z","iopub.execute_input":"2022-01-04T10:30:43.660526Z","iopub.status.idle":"2022-01-04T10:30:43.671307Z","shell.execute_reply.started":"2022-01-04T10:30:43.660495Z","shell.execute_reply":"2022-01-04T10:30:43.670391Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"**We can see there are 7 diffrent face expression**","metadata":{}},{"cell_type":"code","source":"# Creating a function for using for show some images from each categories\ndef imageshow(category):\n  plt.figure(figsize= (8,8))\n  for i in range(1, 10, 1):\n      plt.subplot(3,3,i)\n      img = load_img(train_path+'/'+category+\"/\"+\n                    os.listdir(train_path + \"/\" + category)[i], target_size=(48,48))\n      plt.imshow(img)\n  plt.suptitle(category,fontsize=30)   \n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T11:08:55.248238Z","iopub.execute_input":"2022-01-04T11:08:55.248505Z","iopub.status.idle":"2022-01-04T11:08:55.253938Z","shell.execute_reply.started":"2022-01-04T11:08:55.248472Z","shell.execute_reply":"2022-01-04T11:08:55.252966Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Showing some images from training set","metadata":{}},{"cell_type":"code","source":"#Showing some images from category neutral\nimageshow('neutral')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T11:08:55.891396Z","iopub.execute_input":"2022-01-04T11:08:55.891702Z","iopub.status.idle":"2022-01-04T11:08:56.713126Z","shell.execute_reply.started":"2022-01-04T11:08:55.891672Z","shell.execute_reply":"2022-01-04T11:08:56.712398Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category angry\nimageshow('angry')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T11:08:56.714366Z","iopub.execute_input":"2022-01-04T11:08:56.715185Z","iopub.status.idle":"2022-01-04T11:08:57.483556Z","shell.execute_reply.started":"2022-01-04T11:08:56.715143Z","shell.execute_reply":"2022-01-04T11:08:57.482907Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category sad\nimageshow('sad')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T11:08:57.485132Z","iopub.execute_input":"2022-01-04T11:08:57.485595Z","iopub.status.idle":"2022-01-04T11:08:58.442542Z","shell.execute_reply.started":"2022-01-04T11:08:57.485556Z","shell.execute_reply":"2022-01-04T11:08:58.441752Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category surprise\nimageshow('surprise')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T11:09:03.715979Z","iopub.execute_input":"2022-01-04T11:09:03.716645Z","iopub.status.idle":"2022-01-04T11:09:04.753773Z","shell.execute_reply.started":"2022-01-04T11:09:03.716609Z","shell.execute_reply":"2022-01-04T11:09:04.750220Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category happy\nimageshow('happy')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T11:09:04.755488Z","iopub.execute_input":"2022-01-04T11:09:04.755821Z","iopub.status.idle":"2022-01-04T11:09:05.543245Z","shell.execute_reply.started":"2022-01-04T11:09:04.755776Z","shell.execute_reply":"2022-01-04T11:09:05.542563Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category disgust\nimageshow('disgust')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T11:09:05.544455Z","iopub.execute_input":"2022-01-04T11:09:05.544801Z","iopub.status.idle":"2022-01-04T11:09:06.297437Z","shell.execute_reply.started":"2022-01-04T11:09:05.544766Z","shell.execute_reply":"2022-01-04T11:09:06.296777Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#Showing some images from category fear\nimageshow('fear')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T11:09:06.299030Z","iopub.execute_input":"2022-01-04T11:09:06.299722Z","iopub.status.idle":"2022-01-04T11:09:07.112588Z","shell.execute_reply.started":"2022-01-04T11:09:06.299681Z","shell.execute_reply":"2022-01-04T11:09:07.111898Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Showing some images from validation set","metadata":{}},{"cell_type":"code","source":"# validation set images\nfor category in categories:\n    plt.figure(figsize= (8,8))\n    for j in range(1,10,1):\n        \n        plt.subplot(3,3,j)\n        \n        img = load_img(val_path+'/'+category+\"/\"+\n                    os.listdir(val_path + \"/\" + category)[j], target_size=(48,48))\n        plt.imshow(img)\n    plt.suptitle(category,fontsize=30)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T11:09:07.114038Z","iopub.execute_input":"2022-01-04T11:09:07.114435Z","iopub.status.idle":"2022-01-04T11:09:13.477499Z","shell.execute_reply.started":"2022-01-04T11:09:07.114398Z","shell.execute_reply":"2022-01-04T11:09:13.476836Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"# **Count of images in each category**","metadata":{}},{"cell_type":"code","source":"# count of training images\nfor expression in os.listdir(train_path):\n    print(str(len(os.listdir(train_path +'/' +expression))) + \" \" + expression + \" images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count of validation images\nfor expression in os.listdir(val_path):\n    print(str(len(os.listdir(val_path +'/' +expression))) + \" \" + expression + \" images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data prepration for Self constructed models","metadata":{}},{"cell_type":"code","source":"\nimg_size = 48\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:31:52.814186Z","iopub.execute_input":"2022-01-04T10:31:52.814463Z","iopub.status.idle":"2022-01-04T10:31:52.818067Z","shell.execute_reply.started":"2022-01-04T10:31:52.814434Z","shell.execute_reply":"2022-01-04T10:31:52.817361Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"datagen_train = ImageDataGenerator(horizontal_flip=True,brightness_range=[0.8,1.2],rescale=1./255)\ntrain_generator = datagen_train.flow_from_directory(train_path,\n                                                  target_size=(img_size,img_size),\n                                                  batch_size=batch_size,\n                                                  shuffle=True,\n                                                  color_mode='grayscale',\n                                                  class_mode='categorical')\n\ndatagen_validation = ImageDataGenerator(horizontal_flip=True,brightness_range=[0.8,1.2],rescale=1./255)\nvalidation_generator = datagen_train.flow_from_directory(val_path,\n                                                  target_size=(img_size,img_size),\n                                                  batch_size=batch_size,\n                                                  shuffle=False,\n                                                  color_mode='grayscale',\n                                                  class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:32:10.932991Z","iopub.execute_input":"2022-01-04T10:32:10.933681Z","iopub.status.idle":"2022-01-04T10:32:16.296167Z","shell.execute_reply.started":"2022-01-04T10:32:10.933646Z","shell.execute_reply":"2022-01-04T10:32:16.294801Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"> # **Model Building**","metadata":{}},{"cell_type":"markdown","source":"#  **Self constructed model**","metadata":{}},{"cell_type":"code","source":"# Initialising the CNN\nmodel = Sequential()\n\n# 1 - Convolution\nmodel.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel.add(Conv2D(128,(5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 3rd Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 4th Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Flattening\nmodel.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# output layer \nmodel.add(Dense(7, activation='softmax'))\n\n# compiling the model\nopt = Adam(learning_rate=0.0005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:32:32.189325Z","iopub.execute_input":"2022-01-04T10:32:32.189570Z","iopub.status.idle":"2022-01-04T10:32:32.372988Z","shell.execute_reply.started":"2022-01-04T10:32:32.189542Z","shell.execute_reply":"2022-01-04T10:32:32.372302Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_generator.n//train_generator.batch_size\nsteps_per_epoch","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:32:46.482578Z","iopub.execute_input":"2022-01-04T10:32:46.483302Z","iopub.status.idle":"2022-01-04T10:32:46.488923Z","shell.execute_reply.started":"2022-01-04T10:32:46.483263Z","shell.execute_reply":"2022-01-04T10:32:46.488199Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"validation_steps=validation_generator.n//validation_generator.batch_size\nvalidation_steps","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:32:56.878586Z","iopub.execute_input":"2022-01-04T10:32:56.878828Z","iopub.status.idle":"2022-01-04T10:32:56.884673Z","shell.execute_reply.started":"2022-01-04T10:32:56.878802Z","shell.execute_reply":"2022-01-04T10:32:56.883902Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#  adding various CAllBacks to prevent overfiiting\n# # this decreases the learning rate if the model loss does not decrease \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2, min_lr=0.0001, mode='auto')\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=5,\n                            verbose=1,\n                            restore_best_weights=True)\ncallbacks = [checkpoint, reduce_lr, early_stopping]","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:33:07.026015Z","iopub.execute_input":"2022-01-04T10:33:07.026677Z","iopub.status.idle":"2022-01-04T10:33:07.031759Z","shell.execute_reply.started":"2022-01-04T10:33:07.026642Z","shell.execute_reply":"2022-01-04T10:33:07.031106Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# fitting the model\nhistory = model.fit(\n    x=train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = validation_steps,\n    callbacks=callbacks,\n    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:33:17.011429Z","iopub.execute_input":"2022-01-04T10:33:17.011680Z","iopub.status.idle":"2022-01-04T10:49:16.788272Z","shell.execute_reply.started":"2022-01-04T10:33:17.011653Z","shell.execute_reply":"2022-01-04T10:49:16.786859Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.save(\"CNN_Model1.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:49:34.083888Z","iopub.execute_input":"2022-01-04T10:49:34.084600Z","iopub.status.idle":"2022-01-04T10:50:04.286006Z","shell.execute_reply.started":"2022-01-04T10:49:34.084562Z","shell.execute_reply":"2022-01-04T10:50:04.285237Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model_emo = load_model('./CNN_Model1.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:51:05.073652Z","iopub.execute_input":"2022-01-04T10:51:05.073928Z","iopub.status.idle":"2022-01-04T10:51:05.390370Z","shell.execute_reply.started":"2022-01-04T10:51:05.073897Z","shell.execute_reply":"2022-01-04T10:51:05.389633Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"predictions=model_emo.predict(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:51:07.611968Z","iopub.execute_input":"2022-01-04T10:51:07.612510Z","iopub.status.idle":"2022-01-04T10:51:13.972929Z","shell.execute_reply.started":"2022-01-04T10:51:07.612473Z","shell.execute_reply":"2022-01-04T10:51:13.972017Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":" # Accuracy Score of Our Model\naccuracy=accuracy_score(y_pred=np.argmax(predictions, axis=-1),y_true=validation_data.classes)\nprint(accuracy)   ","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:51:22.388531Z","iopub.execute_input":"2022-01-04T10:51:22.388995Z","iopub.status.idle":"2022-01-04T10:51:22.398371Z","shell.execute_reply.started":"2022-01-04T10:51:22.388956Z","shell.execute_reply":"2022-01-04T10:51:22.397517Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#Plotting Accuracy & Loss\nplt.style.use('dark_background')\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(df['loss'], label='Training Loss')\nplt.plot(df['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(df['accuracy'], label='Training Accuracy')\nplt.plot(df['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T10:25:26.045012Z","iopub.execute_input":"2022-01-04T10:25:26.045716Z","iopub.status.idle":"2022-01-04T10:25:26.713113Z","shell.execute_reply.started":"2022-01-04T10:25:26.045678Z","shell.execute_reply":"2022-01-04T10:25:26.712109Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":" # Accuracy Score of Our Model\nacc=accuracy_score(y_pred=np.argmax(predictions, axis=-1),y_true=validation_generator.classes)\nacc ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute predictions\npredictions = model.predict_generator(generator=validation_data)\ny_pred = [np.argmax(probas) for probas in predictions]\ny_test = validation_data.classes\nclass_names = validation_data.class_indices.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the confusion matrix of our predictions\n\n# # compute predictions\n# predictions = model.predict_generator(generator=validation_data)\n# y_pred = [np.argmax(probas) for probas in predictions]\n# y_test = validation_data.classes\n# class_names = validation_data.class_indices.keys()\n\ndef plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    plt.figure(figsize=(10,8))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')# **Live Class Monitoring System(Face Emotion Recognition)**\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n# compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\n# plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, title='Normalized confusion matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data prepration for Transfer learning**","metadata":{}},{"cell_type":"code","source":"img_size = 244\nbatch_size = 32\n\n# selecting colour mode as rgb as transfer learning is trained on rgb photos and we have grascaled images\ndatagen_train = ImageDataGenerator(rescale=1./255)   \ntrain_generator = datagen_train.flow_from_directory(train_path,\n                                                  target_size=(img_size,img_size),\n                                                  batch_size=batch_size,\n                                                  shuffle=True,\n                                                  color_mode='rgb',\n                                                  class_mode='categorical')\n\ndatagen_validation = ImageDataGenerator(rescale=1./255)\n\nvalidation_generator = datagen_validation.flow_from_directory(val_path,\n                                                  target_size=(img_size,img_size),\n                                                  batch_size=batch_size,\n                                                  shuffle=False,\n                                                  color_mode='rgb',\n                                                  class_mode='categorical')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Vgg16**","metadata":{}},{"cell_type":"code","source":"#using pretrained model, VGG16 architecture\nfrom tensorflow.keras.applications.vgg16 import VGG16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a base model using resnet and loading the pretrained weights\nbase_model = VGG16(input_shape=(224,224,3),include_top = False, weights = 'imagenet')\nbase_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making all the layers except last layer non trainable \nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# our layers - you can add more if you want\nx = Flatten()(base_model.output)\nprediction = Dense(7, activation='softmax')(x)\n# create a model object\nmodel = Model(inputs=base_model.input, outputs=prediction)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    optimizers.Adam(0.01),\n]\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optims[1],\n        metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_generator.n//train_generator.batch_size\nprint(steps_per_epoch)\n\nvalidation_steps=validation_generator.n//validation_generator.batch_size\nprint(validation_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\n# this decreases the learning rate if the model loss does not decrease \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=10, min_lr=0.00001, mode='auto')\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights_mobile_net.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=10,\n                            verbose=1,\n                            restore_best_weights=True)\ncallbacks = [checkpoint, reduce_lr,early_stopping]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n  train_generator,\n  validation_data=validation_generator,\n  epochs=50,\n  steps_per_epoch=steps_per_epoch,\n  validation_steps=validation_steps,\n  callbacks=callbacks,\n  use_multiprocessing=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('vgg16_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MObileNet**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet import MobileNet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_net = MobileNet(input_shape = (224,224,3),include_top = False,weights = \"imagenet\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making all the layers except last layer non trainable \nfor layer in mobile_net.layers:\n    layer.trainable = False\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile_net = MobileNet(\n    input_shape = (224, 224, 3),\n    include_top = False,\n    weights = \"imagenet\",\n    classes = 7\n)\n\nx = mobile_net.layers[-1].output\nglobal_pool = GlobalMaxPool2D(name=\"global_pool\")(x)\nout = Dense(7, activation=\"softmax\", name=\"out_layer\")(global_pool)\n\nmodel = Model(inputs=mobile_net.input, outputs=out)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_data.n//train_data.batch_size\nprint(steps_per_epoch)\n\nvalidation_steps=val_data.n//val_data.batch_size\nprint(validation_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00008,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    min_delta=0.0001,\n    factor=0.25,\n    patience=4,\n    min_lr=1e-7,\n    verbose=1,\n)\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights_mobile_net.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n    checkpoint\n]\nbatch_size = 25\nepochs = 50\n\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    optimizers.Adam(0.01),\n]\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optims[1],\n        metrics=['accuracy']\n)\n\nhistory = model.fit_generator(\n  train_data,\n  validation_data=val_data,\n  epochs=50,\n  steps_per_epoch=steps_per_epoch,\n  validation_steps=validation_steps,\ncallbacks=callbacks,\nuse_multiprocessing=True\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    optimizers.Adam(0.01),\n]\n\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optims[1],\n        metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\n# this decreases the learning rate if the model loss does not decrease \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=10, min_lr=0.00001, mode='auto')\n# to save model weights \ncheckpoint = ModelCheckpoint(\"model_weights_mobile_net.h5\", monitor='val_accuracy',\n                             save_weights_only=True, mode='max', verbose=1)\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=10,\n                            verbose=1,\n                            restore_best_weights=True)\ncallbacks = [checkpoint, reduce_lr,early_stopping]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nI used two callbacks one is `early stopping` for avoiding overfitting training data\nand other `ReduceLROnPlateau` for learning rate.\n\"\"\"\n# early_stopping = EarlyStopping(\n#     monitor='val_accuracy',\n#     min_delta=0.00008,\n#     patience=11,\n#     verbose=1,\n#     restore_best_weights=True,\n# )\n# # to save model weights \n# checkpoint = ModelCheckpoint(\"model_weights_mobilenet.h5\", monitor='val_accuracy',\n#                              save_weights_only=True, mode='max', verbose=1)\n# lr_scheduler = ReduceLROnPlateau(\n#     monitor='val_accuracy',\n#     min_delta=0.0001,\n#     factor=0.25,\n#     patience=4,\n#     min_lr=1e-7,\n#     verbose=1,\n# )\n\n# callbacks = [\n#     early_stopping,\n#     lr_scheduler,\n#     checkpoint\n# ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train_generator.n//train_generator.batch_size\nprint(steps_per_epoch)\nvalidation_steps=validation_generator.n//validation_generator.batch_size\nprint(validation_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n  train_generator,\n  validation_data=validation_generator,\n  epochs=50,\n  steps_per_epoch=steps_per_epoch,\n  validation_steps=validation_steps,\ncallbacks=callbacks\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('mobile_net.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Image generators, for all train, validation, and test set\ntraining_gen=ImageDataGenerator(rescale=1./255)\ntesting_gen=ImageDataGenerator(rescale=1./255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating  Training Dataset\n\ntrain_gen=training_gen.flow_from_directory(train_path,                \n                                           target_size=(48,48),\n                                           batch_size=32,\n                                           color_mode='grayscale',\n                                           class_mode='categorical')\n\n# Creating Test Set\n\ntest_gen=testing_gen.flow_from_directory(val_path,                                       \n                                           target_size=(48,48),  \n                                           batch_size=32,\n                                           color_mode='grayscale',\n                                           class_mode='categorical',\n                                           shuffle= False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.optimizers import Adam,SGD,RMSprop\n\nno_of_classes = 7\n\nmodel = Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n#output layer\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\n\nopt = Adam(lr = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding various Call Backs Like Early stopping to prevent overfitting and Decay Learning Rate to prevent Overshooting\n\ncheckpoint = ModelCheckpoint('./my_model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')          # Adding various Call Backs Like Early stopping to prevent overfitting and Decay Learning Rate to prevent Overshooting\n\n#early stopping\n\nearly_stopping=EarlyStopping(monitor='val_loss',\n                            min_delta=0,\n                            patience=5,\n                            verbose=1,\n                            restore_best_weights=True)\ndecay_lr= ReduceLROnPlateau(monitor='val_loss',\n                           factor=0.2,\n                           patience=3,\n                           verbose=1,\n                           min_delta=0.0001)\ncallbacks=[early_stopping,checkpoint,decay_lr]\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fitting the generator\n\nresults = model.fit_generator(generator=train_gen,\n                                steps_per_epoch=train_gen.n//train_gen.batch_size,\n                                epochs=40,\n                                validation_data = test_gen,\n                                validation_steps = test_gen.n//test_gen.batch_size,\n                                callbacks=callbacks\n                                )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"self_cons.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG 16","metadata":{}},{"cell_type":"code","source":"# construct the training image generator for data augmentation\naug = ImageDataGenerator(\n\trotation_range=20,\n\tzoom_range=0.15,\n\twidth_shift_range=0.2,\n\theight_shift_range=0.2,\n\tshear_range=0.15,\n\thorizontal_flip=True,\n\tfill_mode=\"nearest\")\n\n# load the MobileNetV2 network, ensuring the head FC layer sets are\n# left off\nbaseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n\tinput_tensor=Input(shape=(224, 224, 3)))\n\n# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(128, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n\tlayer.trainable = False\n\n# compile our model\nprint(\"[INFO] compiling model...\")\nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n\tmetrics=[\"accuracy\"])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}